{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction from server using progress reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the necessary libraries and download the data from our database. Progress reports are compiled via database queries, and contain information pertaining to participants' progress in the IC3 digital health platform. The information contained in the progress reports is then used to download data points that meet certain inclusion criteria via in-house API requests.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Updated on 5th of April 2024\n",
    "@author: Dragos Gruia\n",
    "\"\"\"\n",
    "\n",
    "from http.client import HTTPSConnection\n",
    "import json\n",
    "import tqdm\n",
    "from base64 import b64encode\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify which data to download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One needs to specify (in this order) the specific website to which the data is linked, the progress report associated with that website, whether you wish to download speech or cognitive/questionnaire data, the name of the output file, and the name of the directory where the data will be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_domain = 'ic3.cognitron.co.uk' # Website from which we want to download the data\n",
    "ids = pd.read_csv(\"progress_reports/progreportic3_patients_v2_231123.csv\")\n",
    "download_speech = False # If true, only speech files will download\n",
    "output_file = 'patientsv2-23-11-23-cog.obj'\n",
    "output_dir = \"./data_temp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which participants to keep. If all should be kept, comment the first line.\n",
    "ids = ids.loc[ids['status.task_count'] > 2,:]\n",
    "ids = ids.hash\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data via HTTP request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the https connection\n",
    "\n",
    "base_url = \"www.cognitron.co.uk\"\n",
    "c = HTTPSConnection(base_url)\n",
    "\n",
    "#Log in with your username, then use base64 encryption for security\n",
    "\n",
    "user = \"username\"\n",
    "passw = \"password\"\n",
    "userAndPass = b64encode((f\"{user}:{passw}\").encode(\"ascii\")).decode(\"ascii\")\n",
    "headers = { 'Authorization' : f'Basic {userAndPass}' }\n",
    "data_dragos = []\n",
    "weird_ids = []\n",
    "i=0\n",
    "attempts = 0\n",
    "\n",
    "while i < len(ids):\n",
    "    user_id = ids.iloc[i]\n",
    "    try:\n",
    "        \n",
    "        # Download one participant's data at a time and check for data storage errors or corrupted files\n",
    "        \n",
    "        user_id = user_id.replace(\"'\",'\"')\n",
    "        user_id = '-'.join([user_id[0:8], user_id[8:12], user_id[12:16],user_id[16:20],user_id[20:]])\n",
    "        query = f\"/api/v1/data/user/{user_id}/\"\n",
    "        c.request('GET', query, headers=headers)\n",
    "        res = c.getresponse()\n",
    "        res.status\n",
    "        data = res.read()\n",
    "        data_parsed = json.loads(data.decode())\n",
    "        \n",
    "        # Select only the data from the set domain, and the data type (speech or non-speech)\n",
    "        # Create a progress bar to track the download progress \n",
    "        \n",
    "        if data_parsed[\"Success\"]:\n",
    "            df = pd.DataFrame(data_parsed[\"Data\"])\n",
    "            df = df[df.domain == set_domain]\n",
    "            if not df.empty:\n",
    "                df[\"user_id\"] = user_id\n",
    "                if download_speech:\n",
    "                    df = df.loc[df[\"taskname\"].str.contains('IC3_Reading|IC3_Repetition|IC3_SpokenPicture|IC3_NamingTest', regex=True)]\n",
    "                else:\n",
    "                    df = df.loc[~df[\"taskname\"].str.contains('IC3_Reading|IC3_Repetition|IC3_SpokenPicture|IC3_NamingTest', regex=True)]\n",
    "                    \n",
    "                df.reset_index(drop=True,inplace=True)\n",
    "                data_dragos.append(df)\n",
    "                i=i+1\n",
    "                attempts = 0\n",
    "                print(f'Downloading progress {i} / {len(ids)}')\n",
    "                \n",
    "    except:\n",
    "        \n",
    "        # Store information about the participants for which the download failed. \n",
    "        # Re-attempt download 3 up to a maximum of times before moving on to the next data point.     \n",
    "        \n",
    "        attempts = attempts + 1\n",
    "        print(f'Something went wrong with {user_id}. Will reattempt {3-attempts} more times.')\n",
    "        if attempts >=3:\n",
    "            i=i+1\n",
    "            weird_ids.append(user_id)\n",
    "            print(f'Attempted to get data for {user_id} 3 times but failed. Moving on.')\n",
    "\n",
    "# Save the data to a pickle file\n",
    "        \n",
    "fileObj = open(output_file, 'wb')\n",
    "pickle.dump(data_dragos,fileObj)\n",
    "fileObj.close()\n",
    "print('Done.')\n",
    "del data_dragos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add header information to the raw data and save it to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 431.63it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open newly created pickle file \n",
    "\n",
    "fileObj = open(output_file, 'rb')\n",
    "exampleObj = pickle.load(fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "data_file = open(output_file.replace('.obj','.json'), \"a\")\n",
    "\n",
    "# Add header information and write the data to a json file\n",
    "\n",
    "for subj in tqdm(exampleObj):\n",
    "    temp_subj = subj\n",
    "    temp_subj.reset_index(inplace=True)\n",
    "    tasks_no = len(temp_subj)\n",
    "    for tasks in range(0,tasks_no):\n",
    "        raw_data = temp_subj.iloc[tasks,:].data\n",
    "        raw_data['user_id'] = temp_subj.user[tasks]\n",
    "        raw_data['domain'] = temp_subj.domain[tasks]\n",
    "        raw_data['os'] = temp_subj.os[tasks][0]\n",
    "        raw_data['device'] = temp_subj.device[tasks][0]\n",
    "        raw_data['browser'] = temp_subj.browser[tasks][0]\n",
    "        raw_data = json.dumps(raw_data)\n",
    "        data_file.write(raw_data)\n",
    "        data_file.write(\"\\n\")\n",
    "        \n",
    "data_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
