{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc_functions_controls import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/dg519/Documents/normative_paper_github/data'\n",
    "remote_data_folders='/data_ic3online_cognition'\n",
    "supervised_data_folders=['/data_healthy_v1','/data_healthy_v2']\n",
    "folder_structure=['/summary_data','/trial_data','/speech']\n",
    "output_clean_folder ='/data_healthy_cleaned'\n",
    "list_of_tasks = ['IC3_NVtrailMaking','IC3_Orientation', 'IC3_PearCancellation', 'IC3_rs_digitSpan', 'IC3_rs_spatialSpan', 'IC3_rs_PAL', 'IC3_rs_SRT', 'IC3_rs_CRT', 'IC3_SemanticJudgment', 'IC3_i4i_IDED', 'IC3_i4i_motorControl','IC3_calculation', 'IC3_GestureRecognition', 'IC3_AuditorySustainedAttention','IC3_BBCrs_blocks', 'IC3_Comprehension','IC3_rs_oddOneOut', 'IC3_TaskRecall']\n",
    "list_of_questionnaires = ['q_IC3_demographics', 'q_IC3_fatigue','q_IC3_GDS','q_IC3_apathy']\n",
    "list_of_speech = ['IC3_NamingTest','IC3_Reading', 'IC3_Repetition']\n",
    "folder_list = ['data_healthy_v1', 'data_healthy_v2', 'data_ic3online_cognition', 'data_healthy_merged']\n",
    "merged_data_folder ='/data_healthy_combined'\n",
    "data_format = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_preprocessing(root_path, list_of_tasks, list_of_questionnaires, list_of_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We removed 6 people who failed both Orientation and Pear Cancellation, from all tasks.\n",
      "We removed 407 who indicated neurological disorder, 91 with a history of dementia and 92 who are younger than 40.\n",
      "We removed 11 people who cheated.\n",
      "We removed 17 people who failed both Orientation and Pear Cancellation, from all tasks.\n",
      "We removed 33 who indicated neurological disorder, 4 who are younger than 40.\n"
     ]
    }
   ],
   "source": [
    "merged_data_dir = os.path.join(root_path, merged_data_folder.lstrip('/'))\n",
    "inclusion_criteria = create_inclusion_criteria(root_path, remote_data_folders, supervised_data_folders, folder_structure)\n",
    "# Save inclusion criteria\n",
    "inclusion_criteria_path = os.path.join(merged_data_dir, 'inclusion_criteria.csv')\n",
    "inclusion_criteria.to_csv(inclusion_criteria_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographics_preproc(root_path, merged_data_folder, questionnaire_name, inclusion_criteria, folder_structure, data_format, clean_file_extension):\n",
    "    \n",
    "    os.chdir(root_path + merged_data_folder)\n",
    "    try:\n",
    "        df_dem_summary = pd.read_csv(f'.{folder_structure[0]}/{questionnaire_name}{data_format}', low_memory=False)\n",
    "        df_dem_summary = df_dem_summary[df_dem_summary.user_id.isin(inclusion_criteria)]\n",
    "        \n",
    "        df_dem = pd.read_csv(f'.{folder_structure[1]}/{questionnaire_name}_raw{data_format}', low_memory=False)\n",
    "        df_dem = df_dem[df_dem.user_id.isin(inclusion_criteria)]    \n",
    "\n",
    "    except:\n",
    "        print(f'Error in loading {questionnaire_name}. File might not exist.')\n",
    "        return None\n",
    "    \n",
    "    df_dem.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    df_dem =df_dem.drop_duplicates(subset=['user_id','question'], keep='last').reset_index(drop=True)\n",
    "    df_dem_summary =df_dem_summary.drop_duplicates(subset='user_id',keep='last').reset_index(drop=True)\n",
    "    \n",
    "    # Extract demographics of interest\n",
    "    \n",
    "    age = df_dem.groupby(['question']).get_group('<center>Howoldareyou?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    gender = df_dem.groupby(['question']).get_group('<center>Whatisyourbiologicalsex?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    education = df_dem.groupby(['question']).get_group('<center>Whatisyourhighestlevelofeducation?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    device = df_dem.groupby(['question']).get_group('<center>Whatdeviceareyouusingatthemoment?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    english = df_dem.groupby(['question']).get_group('<center>HowwouldyourateyourproficiencyinEnglish?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    depression = df_dem.groupby(['question']).get_group('<center>Areyoucurrentlytakinganymedicationfordepression?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    anxiety = df_dem.groupby(['question']).get_group('<center>Areyoucurrentlytakinganymedicationforanxiety?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    dyslexia = df_dem.groupby(['question']).get_group('<center>DoyouhaveDyslexia,oranyotherproblemswithreadingandwriting?</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "    risks = df_dem.groupby(['question']).get_group('<center>Haveyoueverbeentoldyouhavethefollowing?Tickallthatapplies</center>').loc[:,['response','user_id']].reset_index(drop=True)\n",
    "\n",
    "    # Clean each variable\n",
    "    \n",
    "    age.response = pd.to_numeric(age.response)\n",
    "    age.loc[age.response < 40,'response'] = np.nan\n",
    "    \n",
    "    gender.response = gender.response.replace(['53','55','65','78','71','72'],np.nan)\n",
    "    gender.replace(['Male','Female'],[0,1], inplace=True)\n",
    "\n",
    "    education.response = education.response.replace('1',np.nan)\n",
    "    education.response = education.response.replace('Secondary/HighSchoolDiploma','Secondary/HighSchool-A-levels')\n",
    "    education.response = education.response.replace('Primary/ElementarySchool','SecondarySchool-GCSE')\n",
    "    education.replace(['SecondarySchool-GCSE','Secondary/HighSchool-A-levels','ProfessionalDegree','Bachelor\\'sDegree','Master\\'sDegree','PhD'],[0,1,1,2,3,3], inplace=True)\n",
    "                \n",
    "    device = device.merge(df_dem_summary.loc[:,['user_id','os']], on='user_id', how='outer')\n",
    "    device.response = device.response.fillna(device.os)\n",
    "    device.drop('os',axis=1,inplace=True)\n",
    "    \n",
    "    english.response.replace({'3': 1, '4': 1, 'No': np.nan, '2':1,'1':0}, inplace=True)\n",
    "    depression.response.replace({'No':0, 'Yes':1, 'SKIPPED':0}, inplace=True)   \n",
    "    anxiety.response.replace({'No':0, 'Yes':1, 'SKIPPED':0}, inplace=True)\n",
    "    dyslexia.response.replace({'Yes':1,'No':0,'Tablet':0,'Touchscreen':0,np.nan:0}, inplace=True)\n",
    "    \n",
    "    risks.drop_duplicates(keep='last', inplace=True)\n",
    "    risks.replace(np.nan, ' ', inplace=True)\n",
    "    risks.response = risks.response.str.lower()\n",
    "    risks['diabetes'] = risks.response.apply(lambda x: 'diabetes' in x).replace([True,False], [1,0])\n",
    "    risks['highbloodpressure'] = risks.response.apply(lambda x: 'highbloodpressure' in x).replace([True,False], [1,0])\n",
    "    risks['highcholesterol'] = risks.response.apply(lambda x: ('highcholesterol' in x) or ('highcholesterole' in x)).replace([True,False], [1,0])\n",
    "    risks['heartdisease'] = risks.response.apply(lambda x: 'heartdisease' in x).replace([True,False], [1,0])\n",
    "    risks['kidneydisease'] = risks.response.apply(lambda x: 'kidneydisease' in x).replace([True,False], [1,0])\n",
    "    risks['alcoholdependency'] = risks.response.apply(lambda x: 'alcoholdependency' in x).replace([True,False], [1,0])\n",
    "    risks['over-weight'] = risks.response.apply(lambda x: ('over-weight' in x) or ('overweight' in x)).replace([True,False], [1,0])\n",
    "    risks['long-termsmoker'] = risks.response.apply(lambda x: ('long-termsmoker' in x) or ('longtermsmoker' in x)).replace([True,False], [1,0])\n",
    "    risks['ex-smoker'] = risks.response.apply(lambda x: ('ex-smoker' in x) or ('exsmoker' in x)).replace([True,False], [1,0])\n",
    "    risks.loc[(risks['long-termsmoker'] & risks['ex-smoker']).astype(bool),'ex-smoker'] = 0\n",
    "    risks.response = risks.iloc[:,2:].sum(axis=1)\n",
    "    \n",
    "    age.drop_duplicates(subset=\"user_id\",keep='last',inplace=True)\n",
    "    gender.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    education.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    device.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    english.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    depression.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    anxiety.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    dyslexia.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    risks.drop_duplicates(subset=\"user_id\", keep='last',inplace=True)\n",
    "    \n",
    "    age.rename(columns={'response':'age'}, inplace=True)\n",
    "    gender.rename(columns={'response':'gender'}, inplace=True)\n",
    "    education.rename(columns={'response':'education'}, inplace=True)\n",
    "    device.rename(columns={'response':'device'}, inplace=True)\n",
    "    english.rename(columns={'response':'english'}, inplace=True)\n",
    "    depression.rename(columns={'response':'depression'}, inplace=True)\n",
    "    anxiety.rename(columns={'response':'anxiety'}, inplace=True)\n",
    "    dyslexia.rename(columns={'response':'dyslexia'}, inplace=True)\n",
    "    risks.rename(columns={'response':'risks'}, inplace=True)\n",
    "    \n",
    "    age.dropna(inplace=True)\n",
    "    gender.dropna(inplace=True)\n",
    "    education.dropna(inplace=True)\n",
    "    device.dropna(inplace=True)\n",
    "    english.dropna(inplace=True)\n",
    "    depression.dropna(inplace=True)\n",
    "    anxiety.dropna(inplace=True)\n",
    "    dyslexia.dropna(inplace=True)\n",
    "    risks.dropna(inplace=True)\n",
    "              \n",
    "    # Merge and format\n",
    "    \n",
    "    healthy_demographics = age.merge(gender,on='user_id').merge(education,on='user_id').merge(device,on='user_id').merge(english,on='user_id').merge(depression,on='user_id').merge(anxiety,on='user_id').merge(risks,on='user_id').merge(dyslexia,on='user_id')\n",
    "    healthy_demographics.education = healthy_demographics.education.astype(int)\n",
    "    \n",
    "    one_hot_encoded_data = pd.get_dummies(healthy_demographics, columns = ['device', 'education'])\n",
    "    one_hot_encoded_data.rename(columns={'education_1':'education_Alevels', 'education_2':'education_bachelors','education_3':'education_postBachelors'}, inplace=True)\n",
    "    one_hot_encoded_data.rename(columns={'device_1':'device_tablet', 'device_0':'device_phone'}, inplace=True)\n",
    "    one_hot_encoded_data.rename(columns={'english':'english_secondLanguage'}, inplace=True)\n",
    "    one_hot_encoded_data.replace({True:1, False:0}, inplace=True)\n",
    "    one_hot_encoded_data.loc[:,'gender':'education_postBachelors'] = one_hot_encoded_data.loc[:,'gender':'education_postBachelors'] -0.5\n",
    "\n",
    "    # Save \n",
    "    \n",
    "    one_hot_encoded_data.to_csv(f'.{folder_structure[0]}/{questionnaire_name}{clean_file_extension}{data_format}', index=False)\n",
    "    \n",
    "    return one_hot_encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = demographics_preproc(root_path, merged_data_folder, 'q_IC3_demographics', inclusion_criteria, folder_structure, data_format, '_cleaned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "english_secondLanguage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "depression",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "anxiety",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risks",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "diabetes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "highbloodpressure",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "highcholesterol",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "heartdisease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kidneydisease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alcoholdependency",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "over-weight",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "long-termsmoker",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ex-smoker",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dyslexia",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "device_Laptop/Computer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "device_Phone",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "device_Tablet",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "education_0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "education_Alevels",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "education_bachelors",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "education_postBachelors",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cd347461-bfed-4e28-af3e-6d96452bd7b7",
       "rows": [
        [
         "0",
         "66.0",
         "6f181486-0e14-450e-bfe3-fb85e925adba",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "4.5",
         "-0.5",
         "0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "0.5",
         "-0.5",
         "0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5"
        ],
        [
         "1",
         "54.0",
         "12e7f6c0-f77e-4064-88fc-abb9e1952693",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "1.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5"
        ],
        [
         "2",
         "68.0",
         "54270eee-d9a7-4d44-b72f-f0137372acce",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "2.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5"
        ],
        [
         "3",
         "41.0",
         "68732c3e-9d23-4212-ad3c-22acaddff7e0",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "2.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5"
        ],
        [
         "4",
         "63.0",
         "4b21c478-5926-4c59-b37f-60d6a40ccf43",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5",
         "-0.5",
         "0.5",
         "-0.5"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_secondLanguage</th>\n",
       "      <th>depression</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>risks</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>highbloodpressure</th>\n",
       "      <th>highcholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>long-termsmoker</th>\n",
       "      <th>ex-smoker</th>\n",
       "      <th>dyslexia</th>\n",
       "      <th>device_Laptop/Computer</th>\n",
       "      <th>device_Phone</th>\n",
       "      <th>device_Tablet</th>\n",
       "      <th>education_0</th>\n",
       "      <th>education_Alevels</th>\n",
       "      <th>education_bachelors</th>\n",
       "      <th>education_postBachelors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.0</td>\n",
       "      <td>6f181486-0e14-450e-bfe3-fb85e925adba</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>12e7f6c0-f77e-4064-88fc-abb9e1952693</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>54270eee-d9a7-4d44-b72f-f0137372acce</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>68732c3e-9d23-4212-ad3c-22acaddff7e0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>4b21c478-5926-4c59-b37f-60d6a40ccf43</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age                               user_id  gender  english_secondLanguage  \\\n",
       "0  66.0  6f181486-0e14-450e-bfe3-fb85e925adba    -0.5                    -0.5   \n",
       "1  54.0  12e7f6c0-f77e-4064-88fc-abb9e1952693     0.5                    -0.5   \n",
       "2  68.0  54270eee-d9a7-4d44-b72f-f0137372acce     0.5                    -0.5   \n",
       "3  41.0  68732c3e-9d23-4212-ad3c-22acaddff7e0    -0.5                    -0.5   \n",
       "4  63.0  4b21c478-5926-4c59-b37f-60d6a40ccf43     0.5                    -0.5   \n",
       "\n",
       "   depression  anxiety  risks  diabetes  highbloodpressure  highcholesterol  \\\n",
       "0         0.5     -0.5    4.5      -0.5                0.5              0.5   \n",
       "1        -0.5     -0.5    1.5      -0.5               -0.5             -0.5   \n",
       "2        -0.5     -0.5    2.5      -0.5               -0.5              0.5   \n",
       "3        -0.5     -0.5    2.5      -0.5               -0.5              0.5   \n",
       "4        -0.5     -0.5    0.5      -0.5                0.5             -0.5   \n",
       "\n",
       "   ...  long-termsmoker  ex-smoker  dyslexia  device_Laptop/Computer  \\\n",
       "0  ...             -0.5        0.5       0.5                    -0.5   \n",
       "1  ...             -0.5        0.5      -0.5                     0.5   \n",
       "2  ...             -0.5        0.5      -0.5                    -0.5   \n",
       "3  ...             -0.5        0.5      -0.5                     0.5   \n",
       "4  ...             -0.5       -0.5      -0.5                    -0.5   \n",
       "\n",
       "   device_Phone  device_Tablet  education_0  education_Alevels  \\\n",
       "0           0.5           -0.5         -0.5                0.5   \n",
       "1          -0.5           -0.5         -0.5               -0.5   \n",
       "2          -0.5            0.5         -0.5                0.5   \n",
       "3          -0.5           -0.5         -0.5               -0.5   \n",
       "4          -0.5            0.5         -0.5               -0.5   \n",
       "\n",
       "   education_bachelors  education_postBachelors  \n",
       "0                 -0.5                     -0.5  \n",
       "1                 -0.5                      0.5  \n",
       "2                 -0.5                     -0.5  \n",
       "3                  0.5                     -0.5  \n",
       "4                  0.5                     -0.5  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def demographics_preproc(root_path, merged_data_folder, output_clean_folder, questionnaire_name,\n",
    "                         inclusion_criteria, folder_structure, data_format,\n",
    "                         clean_file_extension):\n",
    "    \"\"\"\n",
    "    Preprocess and clean demographic questionnaire data.\n",
    "\n",
    "    This function loads demographic data from two CSV files (a summary file and a raw file),\n",
    "    filters the data based on the provided inclusion criteria, cleans and transforms the\n",
    "    demographic variables, and returns a one-hot encoded DataFrame of the cleaned data.\n",
    "    The processed DataFrame is also saved to a CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path : str\n",
    "        Root directory path.\n",
    "    merged_data_folder : str\n",
    "        Folder name where the merged data is stored.\n",
    "    questionnaire_name : str\n",
    "        Name of the questionnaire (used in file naming).\n",
    "    inclusion_criteria : list\n",
    "        List of user IDs to be included in the analysis.\n",
    "    folder_structure : list of str\n",
    "        Two-element list with folder paths: first for the summary file, second for the raw file.\n",
    "    data_format : str\n",
    "        File extension (e.g. \".csv\").\n",
    "    clean_file_extension : str\n",
    "        Suffix to be appended to the output file name (e.g. \"_clean\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or None\n",
    "        A one-hot encoded DataFrame containing the cleaned demographic data, or\n",
    "        None if there was an error loading the data.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> df = demographics_preproc(\"/data\", \"merged\", \"survey\", [1, 2, 3],\n",
    "    ...                           [\"/summary\", \"/raw\"], \".csv\", \"_clean\")\n",
    "    >>> df.head()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set working directory\n",
    "    os.chdir(os.path.join(root_path, merged_data_folder.strip('/')))\n",
    "\n",
    "    # Construct file paths (strip / if any)\n",
    "    raw_path = os.path.join(folder_structure[1].strip('/'), f\"{questionnaire_name}_raw{data_format}\")\n",
    "    summary_path = os.path.join(folder_structure[0].strip('/'), f\"{questionnaire_name}{data_format}\")\n",
    "\n",
    "    try:\n",
    "        df_dem = pd.read_csv(raw_path, low_memory=False)\n",
    "        df_dem = df_dem[df_dem.user_id.isin(inclusion_criteria)]\n",
    "        \n",
    "        df_dem_summary = pd.read_csv(summary_path, low_memory=False)\n",
    "        df_dem_summary = df_dem_summary[df_dem_summary.user_id.isin(inclusion_criteria)]\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {questionnaire_name}: {e}. File might not exist.\")\n",
    "        return None\n",
    "\n",
    "    # Drop unwanted columns and duplicates\n",
    "    if 'Unnamed: 0' in df_dem.columns:\n",
    "        df_dem.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "    df_dem = df_dem.drop_duplicates(subset=['user_id', 'question'],keep='last').reset_index(drop=True)\n",
    "    df_dem_summary = df_dem_summary.drop_duplicates(subset='user_id', keep='last').reset_index(drop=True)\n",
    "\n",
    "    def extract_response(df, question_text):\n",
    "        \"\"\"Extract the response and user_id for a given question.\"\"\"\n",
    "        return df.loc[df['question'] == question_text, ['user_id', 'response']].copy().reset_index(drop=True)\n",
    "\n",
    "    # Extract demographics of interest using the question text\n",
    "    age_df = extract_response(df_dem, '<center>Howoldareyou?</center>')\n",
    "    gender_df = extract_response(df_dem, '<center>Whatisyourbiologicalsex?</center>')\n",
    "    education_df = extract_response(df_dem, '<center>Whatisyourhighestlevelofeducation?</center>')\n",
    "    device_df = extract_response(df_dem, '<center>Whatdeviceareyouusingatthemoment?</center>')\n",
    "    english_df = extract_response(df_dem, '<center>HowwouldyourateyourproficiencyinEnglish?</center>')\n",
    "    depression_df = extract_response(df_dem, '<center>Areyoucurrentlytakinganymedicationfordepression?</center>')\n",
    "    anxiety_df = extract_response(df_dem, '<center>Areyoucurrentlytakinganymedicationforanxiety?</center>')\n",
    "    dyslexia_df = extract_response(df_dem, '<center>DoyouhaveDyslexia,oranyotherproblemswithreadingandwriting?</center>')\n",
    "    risks_df = extract_response(df_dem, '<center>Haveyoueverbeentoldyouhavethefollowing?Tickallthatapplies</center>')\n",
    "\n",
    "    # --- Cleaning Functions for Each Variable ---\n",
    "\n",
    "    def clean_age(df):\n",
    "        df['response'] = pd.to_numeric(df['response'], errors='coerce')\n",
    "        df.loc[df['response'] < 40, 'response'] = np.nan\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': 'age'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def clean_gender(df):\n",
    "        df['response'] = df['response'].replace(['53', '55', '65', '78', '71', '72'], np.nan)\n",
    "        df.replace({'Male': 0, 'Female': 1}, inplace=True)\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': 'gender'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def clean_education(df):\n",
    "        df['response'] = df['response'].replace('1', np.nan)\n",
    "        df['response'] = df['response'].replace({\n",
    "            'Secondary/HighSchoolDiploma': 'Secondary/HighSchool-A-levels',\n",
    "            'Primary/ElementarySchool': 'SecondarySchool-GCSE'\n",
    "        })\n",
    "        mapping = {\n",
    "            'SecondarySchool-GCSE': 0,\n",
    "            'Secondary/HighSchool-A-levels': 1,\n",
    "            'ProfessionalDegree': 1,\n",
    "            \"Bachelor'sDegree\": 2,\n",
    "            \"Master'sDegree\": 3,\n",
    "            'PhD': 3\n",
    "        }\n",
    "        df.replace({'response': mapping}, inplace=True)\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': 'education'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def clean_device(df, summary_df):\n",
    "        df = df.merge(summary_df[['user_id', 'os']], on='user_id', how='outer')\n",
    "        df['response'] = df['response'].fillna(df['os'])\n",
    "        df['response'] = df['response'].replace({'Mac OS X': 'Tablet', 'Android': 'Phone', 'Windows': 'Laptop/Computer', 'iOS': 'Phone', 'Chrome OS': 'Laptop/Computer'})\n",
    "        df.drop(columns='os', inplace=True)\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': 'device'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def clean_english(df):\n",
    "        df['response'] = df['response'].replace({'3': 1, '4': 1, 'No': np.nan, '2': 1, '1': 0})\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': 'english'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def clean_binary_response(df, col_name, mapping):\n",
    "        df['response'] = df['response'].replace(mapping)\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': col_name}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def clean_risks(df):\n",
    "        df.drop_duplicates(keep='last', inplace=True)\n",
    "        df.replace(np.nan, ' ', inplace=True)\n",
    "        df['response'] = df['response'].str.lower()\n",
    "        risk_conditions = {\n",
    "            'diabetes': ['diabetes'],\n",
    "            'highbloodpressure': ['highbloodpressure'],\n",
    "            'highcholesterol': ['highcholesterol', 'highcholesterole'],\n",
    "            'heartdisease': ['heartdisease'],\n",
    "            'kidneydisease': ['kidneydisease'],\n",
    "            'alcoholdependency': ['alcoholdependency'],\n",
    "            'over-weight': ['over-weight', 'overweight'],\n",
    "            'long-termsmoker': ['long-termsmoker', 'longtermsmoker'],\n",
    "            'ex-smoker': ['ex-smoker', 'exsmoker']\n",
    "        }\n",
    "        for key, terms in risk_conditions.items():\n",
    "            df[key] = df['response'].apply(lambda x: any(term in x for term in terms)).astype(int)\n",
    "        df.loc[(df['long-termsmoker'] & df['ex-smoker']).astype(bool), 'ex-smoker'] = 0\n",
    "        \n",
    "        # Sum risk flags to obtain a risk score\n",
    "        df['response'] = df[list(risk_conditions.keys())].sum(axis=1)\n",
    "        #df.drop(columns=list(risk_conditions.keys()), inplace=True)\n",
    "        df.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.rename(columns={'response': 'risks'}, inplace=True)\n",
    "        return df\n",
    "\n",
    "    # --- Clean each extracted DataFrame ---\n",
    "    age_df = clean_age(age_df)\n",
    "    gender_df = clean_gender(gender_df)\n",
    "    education_df = clean_education(education_df)\n",
    "    device_df = clean_device(device_df, df_dem_summary)\n",
    "    english_df = clean_english(english_df)\n",
    "    depression_df = clean_binary_response(depression_df, 'depression',\n",
    "                                          {'No': 0, 'Yes': 1, 'SKIPPED': 0})\n",
    "    anxiety_df = clean_binary_response(anxiety_df, 'anxiety',\n",
    "                                       {'No': 0, 'Yes': 1, 'SKIPPED': 0})\n",
    "    dyslexia_df = clean_binary_response(dyslexia_df, 'dyslexia',\n",
    "                                     {'Yes': 1, 'No': 0, 'Tablet': 0, 'Touchscreen': 0, np.nan: 0})\n",
    "    risks_df = clean_risks(risks_df)\n",
    "\n",
    "    # Merge all cleaned data on 'user_id'\n",
    "    dfs = [age_df, gender_df, education_df, device_df, english_df,\n",
    "           depression_df, anxiety_df, risks_df, dyslexia_df]\n",
    "    healthy_demographics = dfs[0]\n",
    "    \n",
    "    for df in dfs[1:]:\n",
    "        healthy_demographics = healthy_demographics.merge(df, how='left', on='user_id')\n",
    "        \n",
    "    healthy_demographics['dyslexia'] = healthy_demographics['dyslexia'].replace(np.nan,0)\n",
    "    healthy_demographics = healthy_demographics.dropna()\n",
    "\n",
    "    # Ensure education is of integer type\n",
    "    healthy_demographics['education'] = healthy_demographics['education'].astype(int)\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    one_hot_encoded_data = pd.get_dummies(healthy_demographics, columns=['device', 'education'])\n",
    "    one_hot_encoded_data.rename(columns={\n",
    "        'education_1': 'education_Alevels',\n",
    "        'education_2': 'education_bachelors',\n",
    "        'education_3': 'education_postBachelors',\n",
    "        'device_1': 'device_tablet',\n",
    "        'device_0': 'device_phone',\n",
    "        'english': 'english_secondLanguage'\n",
    "    }, inplace=True)\n",
    "    one_hot_encoded_data.replace({True: 1, False: 0}, inplace=True)\n",
    "\n",
    "    # Adjust numerical columns by subtracting 0.5 (from gender to education_postBachelors)\n",
    "    cols_to_adjust = one_hot_encoded_data.loc[:, 'gender':'education_postBachelors'].columns\n",
    "    one_hot_encoded_data[cols_to_adjust] = one_hot_encoded_data[cols_to_adjust] - 0.5\n",
    "\n",
    "    # Save the final DataFrame\n",
    "    output_path = os.path.join(root_path, output_clean_folder.strip('/'), folder_structure[0].strip('/'),\n",
    "                               f\"{questionnaire_name}{clean_file_extension}{data_format}\")\n",
    "    one_hot_encoded_data.to_csv(output_path, index=False)\n",
    "\n",
    "    return one_hot_encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id      0\n",
      "education    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_demographics = demographics_preproc(root_path, merged_data_folder, output_clean_folder, 'q_IC3_demographics', inclusion_criteria, folder_structure, data_format, '_cleaned')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_demographics_and_cognition(root_path, output_clean_folder, folder_structure, list_of_tasks, df_demographics, clean_file_extension, data_format):\n",
    "    \n",
    "    os.chdir(root_path + output_clean_folder + folder_structure[0])\n",
    "    \n",
    "    #Do a loop and read the data in each of the tasks\n",
    "\n",
    "    for file in list_of_tasks:\n",
    "        \n",
    "        # Read Task Data for Healthy Participants\n",
    "        temp_healthy_cog = pd.read_csv(f'{file}{clean_file_extension}{data_format}', low_memory=False)\n",
    "        \n",
    "        # Drop duplicates if any\n",
    "        temp_healthy_cog.drop_duplicates(subset='user_id', keep='last', inplace=True)\n",
    "\n",
    "        # Reset the Index\n",
    "        temp_healthy_cog.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Merge Demographics data between patients and controls\n",
    "        task_id = temp_healthy_cog.taskID.iloc[0]       \n",
    "        temp_healthy_cog = temp_healthy_cog.loc[:,['user_id','SummaryScore']]\n",
    "        temp_healthy_cog.rename(columns={'SummaryScore':task_id}, inplace=True)\n",
    "        \n",
    "        df_demographics= pd.merge(df_demographics, temp_healthy_cog,  on=\"user_id\", how=\"left\")\n",
    "    \n",
    "    df_demographics.to_csv('summary_cognition_and_demographics_old.csv')\n",
    "    return df_demographics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = combine_demographics_and_cognition(\n",
    "    root_path, output_clean_folder, folder_structure, list_of_tasks, df_demographics, '_cleaned', data_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def combine_demographics_and_cognition(root_path, output_clean_folder, folder_structure,\n",
    "                                         list_of_tasks, df_demographics,\n",
    "                                         clean_file_extension, data_format):\n",
    "    \"\"\"\n",
    "    Combine demographic data with cognitive task scores.\n",
    "\n",
    "    This function iterates over a list of cognitive task files, reads each file,\n",
    "    cleans the data by dropping duplicates and renaming the summary score column to the task ID,\n",
    "    and then merges the resulting summary scores into the provided demographics DataFrame.\n",
    "    Finally, it saves the combined DataFrame as a CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path : str\n",
    "        The root directory path.\n",
    "    output_clean_folder : str\n",
    "        The folder name containing cleaned cognitive data.\n",
    "    folder_structure : list of str\n",
    "        List of folder structure components; the first element is used to locate the tasks.\n",
    "    list_of_tasks : list of str\n",
    "        List of task file base names (without extension or clean_file_extension).\n",
    "    df_demographics : pd.DataFrame\n",
    "        DataFrame containing the demographic data.\n",
    "    clean_file_extension : str\n",
    "        Suffix appended to task file names (e.g., '_clean').\n",
    "    data_format : str\n",
    "        File format extension (e.g., '.csv').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Merged DataFrame containing demographics and cognitive task scores.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> merged_df = combine_demographics_and_cognition(\n",
    "    ...     \"/data\", \"cleaned\", [\"/tasks\"], [\"task1\", \"task2\"], demographics_df,\n",
    "    ...     \"_clean\", \".csv\"\n",
    "    ... )\n",
    "    >>> merged_df.head()\n",
    "    \"\"\"\n",
    "    # Build the folder path without changing the working directory\n",
    "    tasks_folder = os.path.join(root_path, output_clean_folder.strip('/'), folder_structure[0].strip('/'))\n",
    "    \n",
    "    # Loop through each cognitive task file\n",
    "    for task_file in list_of_tasks:\n",
    "        task_file_path = os.path.join(tasks_folder, f\"{task_file}{clean_file_extension}{data_format}\")\n",
    "        try:\n",
    "            temp_cog = pd.read_csv(task_file_path, low_memory=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {task_file_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Drop duplicate entries for each user and reset the index\n",
    "        temp_cog = temp_cog.drop_duplicates(subset='user_id', keep='last').reset_index(drop=True)\n",
    "        \n",
    "        # Ensure the 'taskID' column exists and use its first value as the new column name\n",
    "        if 'taskID' not in temp_cog.columns:\n",
    "            print(f\"'taskID' column missing in {task_file_path}. Skipping this file.\")\n",
    "            continue\n",
    "        \n",
    "        task_id = temp_cog.loc[0, 'taskID']\n",
    "        \n",
    "        # Select only the 'user_id' and 'SummaryScore' columns and rename 'SummaryScore' to the task_id\n",
    "        temp_cog = temp_cog[['user_id', 'SummaryScore']].rename(columns={'SummaryScore': task_id})\n",
    "        \n",
    "        # Merge the cognitive data with the demographics data on 'user_id'\n",
    "        df_demographics = pd.merge(df_demographics, temp_cog, on='user_id', how='left')\n",
    "    \n",
    "    # Save the merged DataFrame\n",
    "    output_file = os.path.join(tasks_folder, \"summary_cognition_and_demographics_new.csv\")\n",
    "    df_demographics.to_csv(output_file, index=False)\n",
    "    \n",
    "    return df_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demographics = combine_demographics_and_cognition(\n",
    "    root_path, output_clean_folder, folder_structure, list_of_tasks, df_demographics,  '_cleaned', data_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc_functions_patients import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/dg519/Documents/normative_paper_github/data'\n",
    "list_of_tasks = ['IC3_Orientation', 'IC3_PearCancellation', 'IC3_rs_digitSpan', 'IC3_rs_spatialSpan', 'IC3_rs_PAL', 'IC3_rs_SRT', 'IC3_rs_CRT', 'IC3_SemanticJudgment', 'IC3_i4i_IDED', 'IC3_i4i_motorControl','IC3_calculation', 'IC3_GestureRecognition', 'IC3_AuditorySustainedAttention','IC3_BBCrs_blocks', 'IC3_Comprehension', 'IC3_NVtrailMaking','IC3_rs_oddOneOut', 'IC3_TaskRecall']\n",
    "list_of_questionnaires = ['q_IC3_demographics', 'q_IC3_fatigue','q_IC3_GDS','q_IC3_apathy', 'q_IC3_IADL']\n",
    "list_of_speech = ['IC3_NamingTest','IC3_Reading', 'IC3_Repetition']\n",
    "patient_data_folders=['/data_patients_v1','/data_patients_v2']\n",
    "folder_structure=['/summary_data','/trial_data','/speech']\n",
    "output_clean_folder ='/data_patients_cleaned'\n",
    "merged_data_folder ='/data_patients_merged'\n",
    "clean_file_extension='_cleaned'\n",
    "data_format='.csv'\n",
    "clinical_information = '/Users/dg519/Documents/normative_paper_github/data/output_data/patients_database260924.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Merging data across sites...IC3_NamingTest\n",
      "IC3_Reading\n",
      "IC3_Repetition\n",
      "Done\n",
      "Pre-processing IC3_Orientation...Done\n",
      "Pre-processing IC3_PearCancellation...Done\n",
      "Pre-processing IC3_rs_digitSpan...Done\n",
      "Pre-processing IC3_rs_spatialSpan...Done\n",
      "Pre-processing IC3_rs_PAL...Done\n",
      "Pre-processing IC3_rs_SRT...Done\n",
      "Pre-processing IC3_rs_CRT...Done\n",
      "Pre-processing IC3_SemanticJudgment...Done\n",
      "Pre-processing IC3_i4i_IDED...Done\n",
      "Pre-processing IC3_i4i_motorControl...Done\n",
      "Pre-processing IC3_calculation...Done\n",
      "Pre-processing IC3_GestureRecognition...Done\n",
      "Pre-processing IC3_AuditorySustainedAttention...Done\n",
      "Pre-processing IC3_BBCrs_blocks...Done\n",
      "Pre-processing IC3_Comprehension...Done\n",
      "Pre-processing IC3_NVtrailMaking...Done\n",
      "Pre-processing IC3_rs_oddOneOut...Done\n",
      "Pre-processing IC3_TaskRecall...Done\n",
      "Pre-processing q_IC3_demographics...Done\n",
      "Pre-processing q_IC3_fatigue...Questionnaire q_IC3_fatigue does not have a specific preprocessing function.\n",
      "Pre-processing q_IC3_GDS...Questionnaire q_IC3_GDS does not have a specific preprocessing function.\n",
      "Pre-processing q_IC3_apathy...Questionnaire q_IC3_apathy does not have a specific preprocessing function.\n",
      "Pre-processing q_IC3_IADL...Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "df= main_preprocessing(root_path, list_of_tasks, list_of_questionnaires, list_of_speech, clinical_information)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
